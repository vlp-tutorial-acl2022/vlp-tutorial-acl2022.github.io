<!DOCTYPE html>
<html lang="en" class=" usyvdii idc0_336"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link href="style.css" rel="stylesheet">
    <title>ACL 2022 Tutorial - Vision-Language Pretraining: Current Trends and the Future</title>
  </head>
  <body class="vsc-initialized" style="">
    <div class="container bg-light">
        <br>
        <h2>Vision-Language Pretraining: Current Trends and the Future</h2>
        <p class="lead">An <a href="https://www.2022.aclweb.org/">ACL 2022</a> tutorial by <a href="http://www.aidanematzadeh.me">Aida Nematzadeh</a> (DeepMind), <a href="https://www.iro.umontreal.ca/~agrawal/">Aishwarya Agrawal</a> (DeepMind), and <a href="http://www.damienteney.info">Damien Teney</a> (Idiap Research Institute).</p>

        <p class="lead">The goal of this tutorial will be to give an overview of the ingredients needed for working on multimodal problems, particularly vision and language. We will also discuss some of the open problems and promising future directions in this area.

        <p class="lead">Slides and materials will be made available here shortly. Click <a href="mailto:nematzadeh@deepmind.com">here to contact us</a>.</p>
        <br>

    </div>
</body></html>
